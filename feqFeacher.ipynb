{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZE0G8h/dH86hsX83NlgfX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheCaveOfAdullam/study2/blob/main/feqFeacher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfmD3J0slVc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# 기본 경로 설정\n",
        "base_dir = '/mnt/data/ship_data'  # 예시 경로입니다. 실제 경로로 수정하세요.\n",
        "categories = ['normal', 'fault_BB', 'fault_RI', 'fault_SM']\n",
        "\n",
        "# 데이터 로드 및 전처리 함수 정의\n",
        "def load_data(base_dir, split):\n",
        "    X = []\n",
        "    y = []\n",
        "    split_dir = os.path.join(base_dir, split)\n",
        "    for category in categories:\n",
        "        category_dir = os.path.join(split_dir, category)\n",
        "        for file in os.listdir(category_dir):\n",
        "            file_path = os.path.join(category_dir, file)\n",
        "            if file_path.endswith('.csv'):\n",
        "                data = pd.read_csv(file_path, header=None, skiprows=1).values  # 첫 번째 행을 제외하고 데이터 로드\n",
        "                data = pd.to_numeric(data.flatten(), errors='coerce').reshape(-1, 2)  # 여기서 2는 피처의 수입니다.\n",
        "                data = np.nan_to_num(data).astype('float32')  # NaN 값을 0으로 대체하고, float32로 변환\n",
        "                X.append(data[:, 1])  # y 피처만 추출 (두 번째 열)\n",
        "                y.append(category)\n",
        "    X = [np.expand_dims(x, axis=-1) for x in X]  # y 피처만 있으므로 마지막 차원만 추가\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 데이터 로드\n",
        "X_train, y_train = load_data(base_dir, 'train')\n",
        "X_val, y_val = load_data(base_dir, 'validation')\n",
        "X_test, y_test = load_data(base_dir, 'test')\n",
        "\n",
        "# 데이터 차원 변경 (CNN 입력 형식에 맞게)\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_val = np.expand_dims(X_val, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_val_encoded = label_encoder.transform(y_val)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# 원-핫 인코딩\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_val_categorical = to_categorical(y_val_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "# 샘플 데이터 출력\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train_categorical shape:\", y_train_categorical.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val_categorical shape:\", y_val_categorical.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test_categorical shape:\", y_test_categorical.shape)\n",
        "\n",
        "# 첫 번째 샘플 데이터와 레이블 출력\n",
        "print(\"\\nX_train sample data:\", X_train[0])\n",
        "print(\"\\ny_train_categorical sample:\", y_train_categorical[0])\n",
        "\n",
        "# CNN 모델 정의\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# 파라미터 설정\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])  # 입력 형식 조정\n",
        "num_classes = len(categories)\n",
        "\n",
        "# 모델 생성\n",
        "model = create_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(X_train, y_train_categorical, epochs=50, batch_size=32, validation_data=(X_val, y_val_categorical))\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'테스트 손실: {test_loss:.4f}')\n",
        "print(f'테스트 정확도: {test_accuracy*100:.2f}%')\n",
        "\n",
        "# 모델 저장\n",
        "model.save('ship_fault_classification_model.h5')\n",
        "\n",
        "# 학습 과정 시각화\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# 혼동 행렬 출력\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test_categorical, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=categories)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    }
  ]
}